
================================================================================
           TERMINAL-BENCH GREEN AGENT ARCHITECTURE
================================================================================

┌───────────────────────────────────────────────────────────────────────────┐
│                                                                           │
│                         EVALUATION WORKFLOW                               │
│                                                                           │
└───────────────────────────────────────────────────────────────────────────┘


    [1] KICKOFF SCRIPT (src/kickoff.py)
         │
         │  Prepares evaluation configuration:
         │  • Which terminal-bench tasks to run
         │  • White agent URL to evaluate
         │  • Evaluation parameters (attempts, timeout, etc.)
         │
         ├─ Loads config from config.toml via settings
         │
         └─ HTTP POST to http://localhost:9999/agent/messages
                │
                │  A2A Protocol Message:
                │  {
                │    "message": {
                │      "parts": [{
                │        "text": "Launch terminal-bench evaluation..."
                │      }]
                │    }
                │  }
                │
                ▼

    [2] GREEN AGENT (src/green_agent/agent.py) @ port 9999
         │
         ├─ A2AStarletteApplication
         │   └─ Exposes A2A interface
         │
         ├─ TerminalBenchGreenAgentExecutor
         │   │
         │   ├─ Receives A2A message
         │   ├─ Parses task configuration
         │   │
         │   └─ Creates Terminal-Bench Harness:
         │
         │       harness = Harness(
         │           agent_import_path="src.adapters.a2a_white_agent:A2AWhiteAgent",
         │           agent_kwargs={"agent_url": "http://localhost:8001"},
         │           task_ids=["hello-world"],
         │           ...
         │       )
         │
         │   └─ Runs: results = harness.run()
         │
         └───────────────────────────────────────┐
                                                  │
                                                  ▼

    TERMINAL-BENCH HARNESS (from terminal-bench package)
         │
         │  For each task:
         │
         ├─ [a] Load task definition from dataset
         │      • Reads YAML file
         │      • Gets task instruction
         │      • Gets test scripts
         │
         ├─ [b] Spin up Docker environment
         │      • Creates Docker Compose environment
         │      • Starts containers
         │      • Creates tmux session
         │
         ├─ [c] Create agent instance
         │      • Imports: src.adapters.a2a_white_agent.A2AWhiteAgent
         │      • Passes: agent_url="http://localhost:8001"
         │      │
         │      └─ Creates A2AWhiteAgent(agent_url="http://localhost:8001")
         │
         ├─ [d] Run agent on task
         │      │
         │      └─ Calls: agent.perform_task(instruction, session, logging_dir)
         │                │
         │                ▼

    [3] A2A WHITE AGENT ADAPTER (src/adapters/a2a_white_agent.py)
         │
         │  class A2AWhiteAgent(BaseAgent):
         │      # Implements terminal-bench's BaseAgent interface
         │      # Communicates with A2A agent over HTTP
         │
         ├─ perform_task(instruction, session, logging_dir):
         │   │
         │   ├─ Formats task instruction for A2A agent
         │   │   "You are being evaluated on Terminal-Bench..."
         │   │   "TASK: {instruction}"
         │   │   "Use execute_bash_command tool to solve this..."
         │   │
         │   ├─ Sends A2A message to white agent
         │   │   └─ await send_message_to_agent(message, agent_url)
         │   │       │
         │   │       └─ HTTP POST to http://localhost:8001/agent/messages
         │   │
         │   ├─ Receives A2A response
         │   │   └─ Parses response from streaming events
         │   │
         │   └─ Returns AgentResult(failure_mode, tokens, ...)
         │
         └─────────────────────────────────────────┐
                                                    │
                A2A Protocol Message:               │
                {                                   │
                  "message": {                      │
                    "parts": [{                     │
                      "text": "TASK: Create..."     │
                    }]                              │
                  }                                 │
                }                                   │
                                                    ▼

    [4] WHITE AGENT (white_agent/llm_white_agent.py) @ port 8001
         │
         │  Examples:
         │  • llm_white_agent.py (LLM-powered agent with function calling)
         │  • OpenAI Agents SDK + to_a2a()
         │  • Google ADK + to_a2a()
         │  • AgentBeats BeatsAgent
         │  • Custom A2A implementation
         │
         ├─ A2AStarletteApplication
         │   └─ Exposes A2A interface @ http://localhost:8001
         │
         ├─ LLMWhiteAgentExecutor(AgentExecutor)
         │   │
         │   └─ async execute(context, event_queue):
         │       │
         │       ├─ Receives task instruction via A2A
         │       │
         │       ├─ Processes with LLM (OpenAI with function calling):
         │       │   • Understands task
         │       │   • Plans solution
         │       │   • Generates commands
         │       │
         │       ├─ Executes using tools:
         │       │   • execute_bash_command(cmd) → runs in Docker container
         │       │   • Extracts container name from instruction
         │       │   • Iterates until task complete or max iterations
         │       │
         │       └─ Returns solution via A2A
         │
         └─ Tools/MCP Servers:
             • execute_bash_command(cmd) → docker exec in container
             • Safety checks (blocked commands list)
             • Working directory: /app

                                ▲
                                │  A2A Response:
                                │  {
                                │    "result": {
                                │      "parts": [{
                                │        "text": "Task completed..."
                                │      }]
                                │    }
                                │  }
                                │
         ┌──────────────────────┘
         │
         │  Response flows back up the stack:
         │
         └─ [4] White Agent returns solution
              │
              ├─ [3] Adapter receives response, returns AgentResult
              │   │
              │   ├─ [Harness] Receives AgentResult
              │   │   │
              │   │   ├─ [e] Run tests in Docker environment
              │   │   │     • Executes run-tests.sh
              │   │   │     • Captures output
              │   │   │
              │   │   ├─ [f] Parse test results
              │   │   │     • Check which tests passed/failed
              │   │   │     • Determine is_resolved status
              │   │   │
              │   │   └─ [g] Save results
              │   │         • Task results to JSON
              │   │         • Terminal recordings
              │   │         • Logs
              │   │
              │   └─ Repeat for all tasks
              │
              ├─ [2] Green Agent receives BenchmarkResults
              │   │
              │   ├─ Formats results message
              │   └─ Sends A2A response with results
              │
              └─ [1] Kickoff Script displays results


================================================================================
                            KEY COMPONENTS
================================================================================

┌─────────────────────────────────────────────────────────────────────────┐
│ COMPONENT             │ ROLE                    │ INTERFACE             │
├───────────────────────┼─────────────────────────┼───────────────────────┤
│ Kickoff Script        │ Initiates evaluation    │ A2A client            │
│ Green Agent           │ Runs harness            │ A2A server (receives) │
│ Terminal-Bench        │ Orchestrates evaluation │ Python API            │
│ A2A Adapter           │ Protocol translator     │ BaseAgent + A2A       │
│ White Agent           │ Solves tasks            │ A2A server (receives) │
└─────────────────────────────────────────────────────────────────────────┘


================================================================================
                          COMMUNICATION FLOW
================================================================================

                  A2A             Python           A2A
Kickoff ────────────────> Green ──────────> Adapter ──────────> White
Script        (HTTP)      Agent   (method)          (HTTP)      Agent
                            ↓
                         Harness
                            ↓
                      Docker + Tests


================================================================================
                            FILE MAPPING
================================================================================

src/kickoff.py                      ─→  [1] Kickoff Script
src/green_agent/agent.py            ─→  [2] Green Agent
src/green_agent/card.toml           ─→  [2] Green Agent A2A Card
src/adapters/a2a_white_agent.py     ─→  [3] A2A Adapter
src/utils/a2a_client.py             ─→  [3] A2A Communication Helpers
src/config/settings.py              ─→  Configuration Loader
config.toml                         ─→  Main Configuration File
white_agent/llm_white_agent.py      ─→  [4] LLM-Powered White Agent
white_agent/white_agent_card.toml   ─→  [4] White Agent A2A Card

Terminal-bench (installed package):
  terminal_bench/harness/harness.py   ─→  Harness implementation
  terminal_bench/agents/base_agent.py ─→  BaseAgent interface
  terminal_bench/dataset/dataset.py   ─→  Task loading

Scripts:
  scripts/start_green_agent.sh       ─→  Start green agent server
  scripts/start_white_agent.sh       ─→  Start white agent server
  scripts/run_eval.sh                ─→  Run evaluation kickoff
  scripts/check_docker.sh            ─→  Verify Docker setup


================================================================================
                            DATA FLOW
================================================================================

Request:
  config.toml → Settings → Kickoff → A2A Message → Green Agent → Harness Config

Task Execution:
  Task YAML → Instruction → A2A Message → White Agent → Solution → A2A Response

Results:
  Test Output → Parser → TrialResults → BenchmarkResults → Formatted Message


================================================================================
                          PORTS & ENDPOINTS
================================================================================

Green Agent (Evaluator):
  • Port: 9999 (configurable via config.toml [green_agent.port])
  • Endpoints:
    - POST /agent/messages    (receive evaluation requests)
    - GET  /.well-known/agent.json  (agent card)

White Agent (Subject):
  • Port: 8001 (configurable via config.toml [white_agent.port])
  • Endpoints:
    - POST /agent/messages    (receive task instructions)
    - GET  /.well-known/agent.json  (agent card)


================================================================================
                      DIRECTORY STRUCTURE
================================================================================

terminal-bench-green-agent/
│
├── Core Implementation
│   ├── src/
│   │   ├── __init__.py
│   │   ├── __main__.py                  [Main entry point]
│   │   ├── kickoff.py                   [Start evaluation]
│   │   │
│   │   ├── green_agent/
│   │   │   ├── __init__.py
│   │   │   ├── __main__.py              [Green agent entry point]
│   │   │   ├── agent.py                 [Evaluator agent]
│   │   │   └── card.toml                [Green agent A2A card]
│   │   │
│   │   ├── adapters/
│   │   │   ├── __init__.py
│   │   │   └── a2a_white_agent.py       [Protocol adapter]
│   │   │
│   │   ├── config/
│   │   │   ├── __init__.py
│   │   │   └── settings.py              [Config loader]
│   │   │
│   │   └── utils/
│   │       ├── __init__.py
│   │       └── a2a_client.py            [A2A helpers]
│   │
│   └── white_agent/
│       ├── __init__.py
│       ├── __main__.py                  [White agent entry point]
│       ├── llm_white_agent.py           [LLM-powered agent]
│       └── white_agent_card.toml        [White agent A2A card]
│
├── Configuration
│   ├── config.toml                      [Main configuration]
│   ├── .env.example                     [API keys template]
│   └── requirements.txt                 [Dependencies]
│
├── Scripts
│   ├── start_green_agent.sh             [Start green agent]
│   ├── start_white_agent.sh             [Start white agent]
│   ├── run_eval.sh                      [Run evaluation]
│   └── check_docker.sh                  [Check Docker setup]
│
├── Documentation
│   ├── README.md                        [Overview & quick start]
│   ├── SETUP.md                         [Setup guide]
│   └── ARCHITECTURE.txt                 [This file]
│
└── Results (created at runtime)
    └── eval_results/
        └── green_agent_eval_TIMESTAMP/
            ├── results.json             [Overall results]
            ├── run_metadata.json        [Run info]
            └── task_001/                [Per-task results]
                └── task_001.1.run_id/
                    ├── results.json
                    ├── sessions/
                    └── agent_interaction.log


================================================================================
                            CONFIGURATION
================================================================================

Configuration is managed through two files:

1. config.toml - All non-sensitive settings
   • Green/white agent hosts and ports
   • Evaluation parameters (task_ids, attempts, etc.)
   • Dataset settings
   • Logging configuration
   • A2A protocol timeouts

2. .env - Sensitive data (API keys)
   • OPENAI_API_KEY

Configuration loader (src/config/settings.py):
   • Loads config.toml using tomllib
   • Loads .env using python-dotenv
   • Provides type-safe property accessors
   • Validates required settings on startup
   • Environment variables can override TOML settings

Usage in code:
   from src.config import settings

   api_key = settings.openai_api_key
   port = settings.green_agent_port
   tasks = settings.eval_task_ids


================================================================================
                            WHAT HAPPENS WHEN
================================================================================

When you run:  python -m src.kickoff

1. Kickoff script loads config from config.toml via Settings
2. Creates task_config dict with evaluation parameters
3. Wraps config in A2A message
4. POSTs to green agent @ http://localhost:9999/agent/messages
5. Green agent receives message
6. Green agent parses config from message
7. Green agent creates Harness instance with config
8. Green agent calls harness.run()
9. Harness loads tasks from dataset (terminal-bench-core)
10. For each task:
   a. Creates Docker environment for task
   b. Creates A2AWhiteAgent instance with white_agent_url
   c. Calls agent.perform_task(instruction, session, logging_dir)
   d. A2AWhiteAgent formats task instruction with container info
   e. A2AWhiteAgent POSTs to white agent @ http://localhost:8001/agent/messages
   f. White agent receives task via A2A
   g. White agent extracts container name from instruction
   h. White agent uses LLM + function calling to solve
   i. White agent calls execute_bash_command tool repeatedly
   j. Each command runs via: docker exec -w /app <container> bash -c <cmd>
   k. White agent returns solution via A2A streaming response
   l. A2AWhiteAgent receives response from send_message_to_agent()
   m. A2AWhiteAgent returns AgentResult to harness
   n. Harness runs tests (run-tests.sh in container)
   o. Harness scores results (pass/fail)
   p. Harness saves results to eval_results/
11. Harness returns BenchmarkResults to green agent
12. Green agent formats results with accuracy, pass/fail per task
13. Green agent returns results via A2A to kickoff script
14. Kickoff script displays results


================================================================================
                          KEY DESIGN DECISIONS
================================================================================

✓ Why A2A Protocol?
  → Standard agent-to-agent communication
  → Allows any agent implementation (OpenAI, ADK, custom, etc.)
  → Well-defined message format with streaming support
  → Easy to swap out white agents without changing green agent

✓ Why Adapter Pattern?
  → Terminal-bench expects BaseAgent interface
  → White agents expose A2A interface
  → Adapter bridges the two without modifying either
  → Keeps terminal-bench harness reusable

✓ Why Wrap Harness Instead of Reimplementing?
  → Terminal-bench harness is complex (Docker, tmux, testing, etc.)
  → Reusing it ensures correctness and compatibility
  → Easier to maintain and get updates
  → Focus on evaluation logic, not infrastructure

✓ Why Three Separate Processes?
  → Modularity: Each component can be developed/tested independently
  → Flexibility: Can evaluate different agents without restarting green agent
  → Scalability: Can distribute across machines if needed
  → Clear separation of concerns

✓ Why Centralized Configuration?
  → Single source of truth (config.toml)
  → Type-safe access via Settings class
  → Easy to override via environment variables
  → Validates on startup (fail fast)
  → No hardcoded values scattered in code

✓ Why Package Structure (src/)?
  → Clean module organization
  → Proper Python package imports
  → Easy to extend with new components
  → Clear separation of green agent, adapters, config, utils
  → Supports both script and module usage


================================================================================
                          MODULE IMPORT PATHS
================================================================================

Running as scripts:
  python -m src.kickoff
  python -m src.green_agent
  python -m white_agent

Importing in code:
  from src.config import settings
  from src.green_agent.agent import TerminalBenchGreenAgentExecutor
  from src.adapters.a2a_white_agent import A2AWhiteAgent
  from src.utils.a2a_client import send_message_to_agent
  from white_agent.llm_white_agent import LLMWhiteAgentExecutor

Harness agent import path:
  "src.adapters.a2a_white_agent:A2AWhiteAgent"
  → Used by terminal-bench to dynamically import the adapter


================================================================================
                          CRITICAL DETAILS
================================================================================

Container Working Directory:
  • All commands execute at /app inside Docker containers
  • White agent extracts container name from task instruction
  • docker exec -w /app <container> bash -c <command>

A2A Message Flow:
  • Kickoff → Green: Evaluation configuration
  • Adapter → White: Task instruction + container info
  • White → Adapter: Solution as streaming text parts
  • Green → Kickoff: Formatted results

Configuration Loading Order:
  1. config.toml (base settings)
  2. .env file (API keys)
  3. Environment variables (highest priority)

Safety Features:
  • Blocked commands list (configurable)
  • Max iterations limit (prevents infinite loops)
  • Timeouts at multiple levels (A2A, harness, Docker)

Results Storage:
  • eval_results/green_agent_eval_TIMESTAMP/
  • Contains results.json, metadata, per-task logs
  • Includes terminal recordings, command history
  • Agent interaction logs in agent_interaction.log


================================================================================
